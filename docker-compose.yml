version: '3.8'

services:
  app:
    build: .
    ports:
      - "8501:8501"
    environment:
      - STREAMLIT_SERVER_PORT=8501
      - STREAMLIT_SERVER_ADDRESS=0.0.0.0
    volumes:
      - .:/app
    restart: unless-stopped
    networks:
      - ats_network

  # Optional: run Ollama in Docker for fully local AI
  # Uncomment to use local AI with no API keys at all
  # ollama:
  #   image: ollama/ollama
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama_data:/root/.ollama
  #   restart: unless-stopped
  #   networks:
  #     - ats_network

networks:
  ats_network:
    driver: bridge

# volumes:
#   ollama_data:
